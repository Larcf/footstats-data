name: Scrape Virtual Soccer Data

on:
  schedule:
    - cron: '0 */2 * * *'  # A cada 2 horas
  workflow_dispatch:

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        persist-credentials: true

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Cache dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install pip-audit
        pip-audit -r requirements.txt
        
    - name: Run scraper
      run: |
        python scraping.py || {
          echo "Scraping failed" > error.log
          exit 1
        }
      
    - name: Commit and push
      run: |
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action"
        git add live-matches.json
        git commit -m "Update match data" || echo "No changes to commit"
        git push

    - name: Archive data
      run: |
        mkdir -p archives
        cp live-matches.json "archives/$(date +'%Y%m%d_%H%M').json"

    - name: Notify on failure
      if: failure()
      uses: actions/github-script@v6
      with:
        script: |
          github.issues.createComment({
            issue_number: context.issue.number,
            owner: context.repo.owner,
            repo: context.repo.repo,
            body: "⚠️ Scraping falhou! Verifique [aqui](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})"
          })
